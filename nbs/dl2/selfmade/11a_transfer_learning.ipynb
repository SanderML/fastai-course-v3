{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8ce2f0-14fa-4a2b-b78c-7cb8d4a3e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d511f0-d5ab-4a6e-8f9e-706c3b546fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_11 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7a928-1dc5-4864-91f5-227919dc6e0c",
   "metadata": {},
   "source": [
    "# Serializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b725f3a-55ea-478c-9c5c-74a249e597d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGEWOOF_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c94654c-c6f7-4a77-98eb-f04e1b125da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "bs = 64\n",
    "\n",
    "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
    "val_tfms = [make_rgb, CenterCrop(size), np_to_float]\n",
    "\n",
    "il = ImageList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
    "\n",
    "ll.valid.x.tfms = val_tfms\n",
    "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b98165b-236f-4074-8755-f81f027abdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73038a17-5b4f-4265-aa79-12428d08cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = LabelSmoothingCrossEntropy()\n",
    "opt_func = adam_opt(mom=0.9, mom_sqr=0.99, eps=1e-6, wd=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b849c96-8a8c-48d2-a383-2bb59452f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sched_1cycle(lr, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr = combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    return [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2def73a-233d-4b23-9be1-eedf78e0737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "pct_start = 0.5\n",
    "cbsched = sched_1cycle(lr, pct_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb57c6f3-984e-443d-af03-2c12d593f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc17bf5-f719-4af4-8a87-a4803cde9b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(40, cbsched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4026cae4-43fe-47aa-ab1f-e0f1f486b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = learn.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674b64e7-f0cf-4404-94fd-aaa3ea495715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a7d1ec-0a98-4108-a315-fa211713623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.weight, 0.1.weight, 0.1.bias, 0.1.running_mean, 0.1.running_var, 0.1.num_batches_tracked, 1.0.weight, 1.1.weight, 1.1.bias, 1.1.running_mean, 1.1.running_var, 1.1.num_batches_tracked, 2.0.weight, 2.1.weight, 2.1.bias, 2.1.running_mean, 2.1.running_var, 2.1.num_batches_tracked, 4.0.convs.0.0.weight, 4.0.convs.0.1.weight, 4.0.convs.0.1.bias, 4.0.convs.0.1.running_mean, 4.0.convs.0.1.running_var, 4.0.convs.0.1.num_batches_tracked, 4.0.convs.1.0.weight, 4.0.convs.1.1.weight, 4.0.convs.1.1.bias, 4.0.convs.1.1.running_mean, 4.0.convs.1.1.running_var, 4.0.convs.1.1.num_batches_tracked, 4.1.convs.0.0.weight, 4.1.convs.0.1.weight, 4.1.convs.0.1.bias, 4.1.convs.0.1.running_mean, 4.1.convs.0.1.running_var, 4.1.convs.0.1.num_batches_tracked, 4.1.convs.1.0.weight, 4.1.convs.1.1.weight, 4.1.convs.1.1.bias, 4.1.convs.1.1.running_mean, 4.1.convs.1.1.running_var, 4.1.convs.1.1.num_batches_tracked, 5.0.convs.0.0.weight, 5.0.convs.0.1.weight, 5.0.convs.0.1.bias, 5.0.convs.0.1.running_mean, 5.0.convs.0.1.running_var, 5.0.convs.0.1.num_batches_tracked, 5.0.convs.1.0.weight, 5.0.convs.1.1.weight, 5.0.convs.1.1.bias, 5.0.convs.1.1.running_mean, 5.0.convs.1.1.running_var, 5.0.convs.1.1.num_batches_tracked, 5.0.idconv.0.weight, 5.0.idconv.1.weight, 5.0.idconv.1.bias, 5.0.idconv.1.running_mean, 5.0.idconv.1.running_var, 5.0.idconv.1.num_batches_tracked, 5.1.convs.0.0.weight, 5.1.convs.0.1.weight, 5.1.convs.0.1.bias, 5.1.convs.0.1.running_mean, 5.1.convs.0.1.running_var, 5.1.convs.0.1.num_batches_tracked, 5.1.convs.1.0.weight, 5.1.convs.1.1.weight, 5.1.convs.1.1.bias, 5.1.convs.1.1.running_mean, 5.1.convs.1.1.running_var, 5.1.convs.1.1.num_batches_tracked, 6.0.convs.0.0.weight, 6.0.convs.0.1.weight, 6.0.convs.0.1.bias, 6.0.convs.0.1.running_mean, 6.0.convs.0.1.running_var, 6.0.convs.0.1.num_batches_tracked, 6.0.convs.1.0.weight, 6.0.convs.1.1.weight, 6.0.convs.1.1.bias, 6.0.convs.1.1.running_mean, 6.0.convs.1.1.running_var, 6.0.convs.1.1.num_batches_tracked, 6.0.idconv.0.weight, 6.0.idconv.1.weight, 6.0.idconv.1.bias, 6.0.idconv.1.running_mean, 6.0.idconv.1.running_var, 6.0.idconv.1.num_batches_tracked, 6.1.convs.0.0.weight, 6.1.convs.0.1.weight, 6.1.convs.0.1.bias, 6.1.convs.0.1.running_mean, 6.1.convs.0.1.running_var, 6.1.convs.0.1.num_batches_tracked, 6.1.convs.1.0.weight, 6.1.convs.1.1.weight, 6.1.convs.1.1.bias, 6.1.convs.1.1.running_mean, 6.1.convs.1.1.running_var, 6.1.convs.1.1.num_batches_tracked, 7.0.convs.0.0.weight, 7.0.convs.0.1.weight, 7.0.convs.0.1.bias, 7.0.convs.0.1.running_mean, 7.0.convs.0.1.running_var, 7.0.convs.0.1.num_batches_tracked, 7.0.convs.1.0.weight, 7.0.convs.1.1.weight, 7.0.convs.1.1.bias, 7.0.convs.1.1.running_mean, 7.0.convs.1.1.running_var, 7.0.convs.1.1.num_batches_tracked, 7.0.idconv.0.weight, 7.0.idconv.1.weight, 7.0.idconv.1.bias, 7.0.idconv.1.running_mean, 7.0.idconv.1.running_var, 7.0.idconv.1.num_batches_tracked, 7.1.convs.0.0.weight, 7.1.convs.0.1.weight, 7.1.convs.0.1.bias, 7.1.convs.0.1.running_mean, 7.1.convs.0.1.running_var, 7.1.convs.0.1.num_batches_tracked, 7.1.convs.1.0.weight, 7.1.convs.1.1.weight, 7.1.convs.1.1.bias, 7.1.convs.1.1.running_mean, 7.1.convs.1.1.running_var, 7.1.convs.1.1.num_batches_tracked, 10.weight, 10.bias'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(st.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9980e328-2f74-4a81-94b7-a2db8ced7dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st['10.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971068ca-eadc-4598-a208-d42738e3e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_path = path/'models'\n",
    "mdl_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aa0bb4b-d497-42dd-819d-a2fffa55a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(st, mdl_path/'iw5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0384fa9-dc13-4736-8078-5a9d24bb9287",
   "metadata": {},
   "source": [
    "# Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3464c31b-efdd-47bc-9c51-7062707b0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5e8acd-e6ed-4447-9e4a-b2482b16ee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/sandmann/.fastai/data/oxford-iiit-pet/small-256'),\n",
       " Path('/home/sandmann/.fastai/data/oxford-iiit-pet/image_gen'),\n",
       " Path('/home/sandmann/.fastai/data/oxford-iiit-pet/crappy'),\n",
       " Path('/home/sandmann/.fastai/data/oxford-iiit-pet/annotations'),\n",
       " Path('/home/sandmann/.fastai/data/oxford-iiit-pet/models'),\n",
       " Path('/home/sandmann/.fastai/data/oxford-iiit-pet/small-96'),\n",
       " Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c7f57d-eb0e-4f4e-a727-df26779e2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_path = pets/'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc972bb4-472f-4a79-b644-f84f29362679",
   "metadata": {},
   "outputs": [],
   "source": [
    "il = ImageList.from_files(pets_path, tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b850f0b-02c3-4f0f-9888-0c02733fe6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageList (7390 items)\n",
       "[Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Birman_115.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/leonberger_142.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Bombay_68.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/japanese_chin_26.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/saint_bernard_149.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Ragdoll_41.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/japanese_chin_32.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Ragdoll_68.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Persian_202.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/scottish_terrier_143.jpg')...]\n",
       "Path: /home/sandmann/.fastai/data/oxford-iiit-pet/images"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffcb6e2d-0624-45f8-ac6a-8960cb2b390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_splitter(fn, p_valid): return random.random() < p_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1ad9a02-e554-4524-9002-ad7731bdc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40348cd6-db65-472b-953b-cdb72ebf5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c149a9a7-47e4-4cb5-8df3-f5752165b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: ImageList (6667 items)\n",
       "[Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Birman_115.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Bombay_68.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/japanese_chin_26.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/saint_bernard_149.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Ragdoll_41.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/japanese_chin_32.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Persian_202.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/english_setter_157.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Bombay_215.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Bengal_69.jpg')...]\n",
       "Path: /home/sandmann/.fastai/data/oxford-iiit-pet/images\n",
       "Valid: ImageList (723 items)\n",
       "[Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/leonberger_142.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Ragdoll_68.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/scottish_terrier_143.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/havanese_80.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/newfoundland_156.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/english_cocker_spaniel_167.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_118.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_105.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/chihuahua_54.jpg'), Path('/home/sandmann/.fastai/data/oxford-iiit-pet/images/boxer_107.jpg')...]\n",
       "Path: /home/sandmann/.fastai/data/oxford-iiit-pet/images"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16fca53a-6266-4f0a-8273-1390fc0c4553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Birman_115.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = il.items[0].name\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "240939a5-aaf8-44cd-8161-707fda3e0022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Birman'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)_\\d+\\.jpg$', n)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69b22dd6-ae6d-4809-a1b9-7d0bc6a9cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pet_labeler(fn): return re.findall(r'^(.*)_\\d+\\.jpg$', fn.name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4310797f-7711-4d91-a9e3-6ddc7f0b2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = CategoryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99fa0d0b-75cb-4214-bf3f-b9e19f7de9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = label_by_func(sd, pet_labeler, proc_y=proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "242144f6-6d49-48f0-ae52-1a925bc2d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Birman, Bombay, japanese_chin, saint_bernard, Ragdoll, Persian, english_setter, Bengal, great_pyrenees, basset_hound, Egyptian_Mau, american_bulldog, english_cocker_spaniel, newfoundland, american_pit_bull_terrier, samoyed, staffordshire_bull_terrier, shiba_inu, german_shorthaired, miniature_pinscher, leonberger, yorkshire_terrier, scottish_terrier, Sphynx, havanese, beagle, keeshond, boxer, British_Shorthair, pomeranian, Abyssinian, Maine_Coon, pug, wheaten_terrier, Russian_Blue, chihuahua, Siamese'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(proc.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84fdde6f-7706-454d-b4e4-3077251ea6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.valid.x.tfms = val_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff9fcfae-367c-4c93-95c9-685187239c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out = len(proc.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f043894-7376-4d7d-8ae2-bd51bfe30c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ll.to_databunch(bs, c_in=3, c_out=c_out, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24ec1ba0-0ceb-41f5-9612-997a15307090",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "793f0068-4449-4260-bf34-9aa6399f820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(5, cbsched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1b1db-8f11-42c5-be7c-a8febf748217",
   "metadata": {},
   "source": [
    "# Custom head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e311eff-5ed4-45fe-bc5d-e3321e656103",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eacbaed-bb01-4a07-a530-c92bddcda6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = torch.load(mdl_path/'iw5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02f4b875-35e3-4b76-b476-03cbe0c95b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee8beffa-3214-4b02-9c11-52157ae88013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.load_state_dict(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd69d801-6b43-4588-b550-9c7480e7abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = [i for i,o in enumerate(m.children()) if isinstance(o, nn.AdaptiveAvgPool2d)][0]\n",
    "m_cut = m[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5d27e80-d79b-4cc7-9167-e9a24653d0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = get_batch(data.valid_dl, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eccdc7f9-6ca5-4591-89ef-070bacc8a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandmann/anaconda3/envs/fastbook/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "pred = m_cut(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c87c2fd-fcba-45ae-a2a8-bf9a7b065987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 512, 4, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9000d121-d575-4d89-b032-47936aa11d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = pred.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3d92acd-bffb-4599-b009-0660e63f175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=1):\n",
    "        super().__init__()\n",
    "        self.output_size = sz\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "        \n",
    "    def forward(self, x): return torch.cat([self.ap(x), self.mp(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e8d1dbf-9ab9-41d3-92fb-c53d0e940939",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 40\n",
    "\n",
    "m_new = nn.Sequential(m_cut,\n",
    "                     AdaptiveConcatPool2d(), Flatten(),\n",
    "                     nn.Linear(2*ni, data.c_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "014d995d-29e3-4524-a0c5-253fcdf49ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = m_new.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd4049df-8247-4557-9a1b-dd40068fb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(5, cbsched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6406fd-bc39-4312-aa62-5f52ed757bc9",
   "metadata": {},
   "source": [
    "# adapt_model and gradual unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b44eedf6-a2a9-4c70-b746-0d259e8a1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_model(learn, data):\n",
    "    cut = [i for i,o in enumerate(learn.model.children()) if isinstance(o, nn.AdaptiveAvgPool2d)][0]\n",
    "    m_cut = learn.model[:cut]\n",
    "    xb,yb = get_batch(data.valid_dl, learn)\n",
    "    pred = m_cut(xb)\n",
    "    ni = pred.shape[1]\n",
    "    \n",
    "    m_new = nn.Sequential(m_cut,\n",
    "                         AdaptiveConcatPool2d(), Flatten(),\n",
    "                         nn.Linear(2*ni, data.c_out))\n",
    "    learn.model = m_new.to(xb.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3e18bcf-8d3d-4c4b-97dd-9ee5af3201b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette)\n",
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "855b91f5-8616-4fe3-b792-5e11f33891e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapt_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a75026b2-b8e9-4b26-8cb8-56283206ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in learn.model[0].parameters(): p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f34e5cd-a403-464f-a30d-6e551ff0163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(3, sched_1cycle(1e-2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55c8c9d2-4174-4608-8a70-e1fd05258b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in learn.model[0].parameters(): p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36756799-e256-4958-bed1-3f9a089f5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(5, cbsched, reset_opt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc6a8e-9f58-43af-a417-ee7c38c9cce9",
   "metadata": {},
   "source": [
    "# Batch Norm Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd972adc-6e7a-442a-9a5e-412463dbfeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette)\n",
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n",
    "adapt_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3807ab70-7125-4d0e-b22f-bf6620a79e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mod(m, f):\n",
    "    f(m)\n",
    "    for l in m.children(): apply_mod(l, f)\n",
    "    \n",
    "def set_grad(m, b):\n",
    "    if isinstance(m, (nn.Linear, nn.BatchNorm2d)): return\n",
    "    if hasattr(m, 'weight'):\n",
    "        for p in m.parameters(): p.requires_grad_(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b968746-cafa-4a32-ab7a-ddc18b95cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mod(learn.model, partial(set_grad, b=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4e9072b-d42f-4016-8895-b34fea6dde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(3, sched_1cycle(1e-2, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41d0dca0-d446-4bba-8931-6f67329f793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mod(learn.model, partial(set_grad, b=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b67e4aa5-ef1c-4098-a7eb-fc45e1a043e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(5, cbsched, reset_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f46dd149-76de-47bc-8a33-2eca6d4c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.apply(partial(set_grad, b=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e767a-b913-43d2-8e1f-2bb34111dc6b",
   "metadata": {},
   "source": [
    "# Discriminative LR and param groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92f8d60a-8eda-4a00-a3ea-7c737f627dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aab08c0a-699a-42d4-8372-38dfdf8840ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n",
    "adapt_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32b0e522-76a1-4658-bc90-57b0d0cb9c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_splitter(m):\n",
    "    def _bn_splitter(l, g1, g2):\n",
    "        if isinstance(l, nn.BatchNorm2d): g2 += l.parameters()\n",
    "        elif hasattr(l, 'weight'): g1 += l.parameters()\n",
    "        for ll in l.children(): _bn_splitter(ll, g1, g2)\n",
    "        \n",
    "    g1,g2 = [],[]\n",
    "    _bn_splitter(m[0], g1, g2)\n",
    "    g2 += m[1:].parameters()\n",
    "\n",
    "    return g1,g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8a4129d-1741-48a0-ad13-472b9f5eaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = bn_splitter(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f164f81-80d3-46d8-a4b5-d6f721b37acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(a)+len(b), len(list(learn.model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a26defc-6630-40ad-b0b7-60c36446fc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'after_backward',\n",
       " 'after_batch',\n",
       " 'after_cancel_batch',\n",
       " 'after_cancel_epoch',\n",
       " 'after_cancel_train',\n",
       " 'after_epoch',\n",
       " 'after_fit',\n",
       " 'after_loss',\n",
       " 'after_pred',\n",
       " 'after_step',\n",
       " 'begin_batch',\n",
       " 'begin_epoch',\n",
       " 'begin_fit',\n",
       " 'begin_validate'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Learner.ALL_CBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8167b721-27b2-4169-81f4-713080714fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from types import SimpleNamespace\n",
    "cb_types = SimpleNamespace(**{o:o for o in Learner.ALL_CBS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0e38d54-451e-4adb-84db-397f2b552f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DebugCallback(Callback):\n",
    "    _order = 999\n",
    "    def __init__(self, cb_name, f=None): self.cb_name,self.f = cb_name,f\n",
    "    def __call__(self, cb_name):\n",
    "        if cb_name == self.cb_name:\n",
    "            if self.f: self.f(self.run)\n",
    "            else: set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c35cfce-1598-4b01-82cd-5b78e0e246e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_det(o):\n",
    "    print(len(o.opt.param_groups), o.opt.hypers, sep='\\n')\n",
    "    raise CancelTrainException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8f0bb26-5829-408d-824f-aedb33b898ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sched_1cycle(lrs, pct_start=0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n",
    "    lrs = listify(lrs)\n",
    "    phases = create_phases(pct_start)\n",
    "    sched_lr = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5)) for lr in lrs]\n",
    "    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n",
    "    \n",
    "    return [ParamScheduler('lr', sched_lr), ParamScheduler('mom', sched_mom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89242783-17e5-4830-8e41-1045f6bb115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_lr_sched = sched_1cycle([0,3e-2], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f76ebe1-1765-467f-b70f-58c883e76924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = cnn_learner(xresnet18, data, loss_func, opt_func, c_out=10, norm=norm_imagenette, splitter=bn_splitter)\n",
    "\n",
    "learn.model.load_state_dict(torch.load(mdl_path/'iw5'))\n",
    "adapt_model(learn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b909d2db-1c53-41f7-bfa5-cd9c06456c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[{'mom': 0.9499999999999997, 'mom_sqr': 0.99, 'eps': 1e-06, 'wd': 0.01, 'lr': 0.0, 'sqr_mom': 0.99}, {'mom': 0.9499999999999997, 'mom_sqr': 0.99, 'eps': 1e-06, 'wd': 0.01, 'lr': 0.0030000000000000512, 'sqr_mom': 0.99}]\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1, disc_lr_sched + [DebugCallback(cb_types.after_batch, _print_det)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70562b9a-a1b8-4765-b72a-ea695ef3ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.545230</td>\n",
       "      <td>0.362082</td>\n",
       "      <td>2.300637</td>\n",
       "      <td>0.450899</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.246772</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>2.307571</td>\n",
       "      <td>0.439834</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.970470</td>\n",
       "      <td>0.545973</td>\n",
       "      <td>1.899560</td>\n",
       "      <td>0.576764</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn.fit(3, disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c8bffe9-b2dc-478a-9b7b-c41804fd4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_lr_sched = sched_1cycle([1e-3,1e-2], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ed3ed2f-e828-4102-ac4a-3203d1ac66db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.817210</td>\n",
       "      <td>0.603720</td>\n",
       "      <td>1.872048</td>\n",
       "      <td>0.572614</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.836615</td>\n",
       "      <td>0.590970</td>\n",
       "      <td>2.411371</td>\n",
       "      <td>0.410788</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.694964</td>\n",
       "      <td>0.650068</td>\n",
       "      <td>1.812372</td>\n",
       "      <td>0.604426</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.545127</td>\n",
       "      <td>0.702415</td>\n",
       "      <td>1.682303</td>\n",
       "      <td>0.654219</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.453181</td>\n",
       "      <td>0.740363</td>\n",
       "      <td>1.610572</td>\n",
       "      <td>0.688797</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn.fit(5, disc_lr_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6a8d4a53-f0eb-479f-bea8-c0e5c8d3bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 11a_transfer_learning.ipynb to exp/nb_11a.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 11a_transfer_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ea832-9067-4329-9f43-27ae13885b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
