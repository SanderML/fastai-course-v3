{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c262b1-4028-4ddb-a112-c52138747af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35ed00d-8f39-4762-b531-dd4301491e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8097f9-1978-4510-9380-f93d23143633",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00441979-815e-46d0-9dd8-5603acfa652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data2():\n",
    "    mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),\n",
    "                 get_items = get_image_files,\n",
    "                 splitter = GrandparentSplitter('training', 'testing'),\n",
    "                 get_y = parent_label)\n",
    "    dls = mnist.dataloaders(untar_data(URLs.MNIST))\n",
    "    x_train, y_train = zip(*dls.train_ds)\n",
    "    x_valid, y_valid = zip(*dls.valid_ds)\n",
    "    \n",
    "    x_train = tensor(list(map(array, x_train)), dtype=torch.float32).view(len(dls.train_ds), -1)\n",
    "    x_valid = tensor(list(map(array, x_valid)), dtype=torch.float32).view(len(dls.valid_ds), -1)\n",
    "    y_train = tensor(y_train)\n",
    "    y_valid = tensor(y_valid)\n",
    "    \n",
    "    x_mean = x_train.mean()\n",
    "    x_std = x_train.std()\n",
    "    x_train, x_valid = normalize(x_train, x_mean, x_std), normalize(x_valid, x_mean, x_std)\n",
    "    x_train, x_valid = x_train / 255.0, x_valid / 255.0\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b38edaf0-6c0c-44af-8091-8b16e78a8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d8b7be-99b1-4235-b6bc-52b86fe7d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254a1cb4-7a64-425a-9492-9dcc372d2275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2db4af7-eb18-4ea9-95cb-228a4359e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = int(y_train.max() + 1)\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a69c72-9cb2-4cb0-a8e0-0523d97a0d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1514933-6d27-4b1c-87c4-7e724aac1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m,nh,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fa5689-bbea-476a-9ca0-8168b4fc0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794fa282-425e-4596-8f23-1c3da2e8427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eccabd9b-879a-4760-93fd-cf912aeef9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e08bde-3540-421c-b20e-47d9b59fa990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(pred): pred - pred.exp().sum(dim=-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd9604b-cb20-4c5b-ad60-a6b3e99f04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x - m[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37e669ab-c6f1-4093-83de-2f2e583131eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(pred): return pred - pred.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4597dc-e854-4bc1-9e73-eb7556eb7ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c110c26e-ea3b-46dd-8758-66b50f2daf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(pred, target): return -pred[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfcc8d52-c5bb-4ba1-9aae-d707db030262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a3e2aa-608b-4181-8fe0-b2eb88350b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0129, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "365ef22f-e47e-4741-a783-24297d9baba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3052, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(log_softmax(pred), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6382d0c0-6045-47e2-a174-cdf716027982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3056, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(F.log_softmax(pred, -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2aa2c59-50c5-4bb7-b43e-e52f0207f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "574aa7bc-cfdc-4bae-8d9a-dffea0f19d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target): return (pred.argmax(-1) == target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a87d99cf-82e6-4b87-a390-c253b78c88b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0986)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred, y_train) # ~ 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28a70aa3-8ed6-4dd6-b72b-24077266495b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0307,  0.0831,  0.0322, -0.0387,  0.0954, -0.1065,  0.1058, -0.1409,\n",
       "          0.0788, -0.0204], grad_fn=<SelectBackward>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs  = 64\n",
    "\n",
    "xb = x_train[:bs]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d28c1dc0-d174-42bf-90df-b1ff7e6143c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2230, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "599ed4bc-73bc-4a23-b501-659a091c9af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29a6068c-f7a0-47e5-bda4-3193c1b0e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a5a4106-eff3-4c43-af72-b7e8ded63e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for p in model.parameters(): p -= p.grad * lr\n",
    "            model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f86c1dea-c0d5-4537-90d1-fa9a7020c66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0014, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb), accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb6d18-d7ff-4919-823a-b16d7dfaaf30",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a5d913d-a377-444f-a1cd-32e50f689b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0598adb6-7784-4d85-bbeb-7aa69fe16111",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23df3deb-8a1e-45d0-97c8-26e92e74fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0ea3426-589f-499b-8d4c-734fcccb0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90d5231b-3363-41e0-ad4f-8e362961277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0015, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8496183-d374-472e-881e-f46c637e1c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92eab057-1d30-4a6e-9d3c-7766441899fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 784]), torch.Size([32]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f8753-dae7-49d4-b4dc-65f906171e7d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4b123e2-73fd-4d8f-9554-cdb85b32046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self,i): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10bc8b61-bccd-43fc-83ed-0ed4b0204ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "valid_ds = Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c550610f-ca70-4b56-9bc3-6ee95fb016a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35eec9-019e-4ec6-bbe8-1c845cedbfa2",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "196f9da2-0040-4375-894f-d8def494b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self): \n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf1bcaa0-1f52-4933-9e3a-887fbec33e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3784f966-4bd1-4eab-852c-5bd2a8291560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96475f23-5a05-4f33-ae4a-6166a10e0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cb61677-3abf-409f-9cf2-060c10bccb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"returns model and optimizer\"\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,c))\n",
    "    return model, torch.optim.Adam(model.parameters(), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78d92464-ba45-4ee2-b2bb-799eae04bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9504e8b1-a456-425f-8341-de6508c49c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.4138, grad_fn=<NllLossBackward>), tensor(0.))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab0ddbbf-06b8-4fce-81ce-fb28dfe2b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "162f6587-c672-4e9d-8851-e8f22d82a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_accuracy(model, xb, yb):\n",
    "    return loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45448574-83e6-49b3-96da-e5f60f1f314d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0008, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_accuracy(model, xb, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14821e-66c3-48be-bd1e-3f5cdc4b3058",
   "metadata": {},
   "source": [
    "## RandomSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4aa1d2ec-dc5e-4e92-a215-280ca6803d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n, self.bs, self.shuffle = len(ds), bs, shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "259ba01c-e937-4e71-9e1c-3eefaaa2aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98c6a1d0-f473-45ff-bb5c-dfa91af9b352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds, 3, False)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6be28c3-0438-4026-8959-a6290f20c2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([8, 1, 5]), tensor([0, 6, 7]), tensor([3, 9, 2]), tensor([4])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds, 3, True)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7a7fef5-31f6-43c8-ba86-72e90a8b9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xb, yb = zip(*b)\n",
    "    return torch.stack(xb), torch.stack(yb)\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds, self.sampler, self.collate_fn = ds, sampler, collate\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5107430d-dac1-4f1f-9013-1cef4a11f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, True)\n",
    "valid_samp = Sampler(valid_ds, bs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1182e220-614e-4605-b8b4-bb4b6c3d928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, train_samp, collate)\n",
    "valid_dl = DataLoader(valid_ds, valid_samp, collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "679650a8-39af-4aa0-9307-07870d4ec0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2498419-7136-4d0f-986b-5e2e8bd936af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0340e9a7-97eb-4e40-b05d-bdddb74f1639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.2956, grad_fn=<NllLossBackward>), tensor(0.1250))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_and_accuracy(model, xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f25eb33-40a1-4474-8621-e206b1608241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2927, grad_fn=<NllLossBackward>), tensor(0.8438))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_and_accuracy(model, xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3589c5a-f41c-4f5f-872f-9efb77b85431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68a017e6-2674-46e6-bba5-74b34ebf327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4831f11-7c53-40ab-88ea-5dc851863b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bd9f733-3242-4260-8a9c-65dbf7db10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5a48b55-b777-4e38-9d65-4992906425a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd94c67c-ec93-4de5-bc20-7f3e353e8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "226d7e59-b42a-4bde-b05d-5c6ecadc099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41da5ca1-dbfa-405b-adb4-3d00fefd1219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1058, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_and_accuracy(model, xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e131d2f7-beb6-41af-a6b0-945a1fb1cf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f50947b0-c70b-41e4-8f9b-92800a8a6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dl, valid_dl, loss_func, opt, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc =  0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc += accuracy(pred, yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f01a4fa3-2ff7-40e8-b9e2-137c02525180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return DataLoader(train_ds, bs, True, **kwargs), DataLoader(valid_ds, bs*2, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d05a3387-ea45-479c-8a33-c6be8401abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a65c299-b800-472b-96ed-78d1e4fc025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "430d4adc-ba9e-47a9-aaac-c3e1ef5c8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5e42965-3095-433f-91e2-e76852f458b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d1b0257-efc6-47db-8fd0-535173d7cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.9226) tensor(0.4316)\n",
      "1 tensor(1.1885) tensor(0.5807)\n",
      "2 tensor(0.9023) tensor(0.7118)\n",
      "3 tensor(0.5563) tensor(0.8329)\n",
      "4 tensor(1.0962) tensor(0.6308)\n"
     ]
    }
   ],
   "source": [
    "loss,acc = fit(model, train_dl, valid_dl, loss_func, opt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115bb953-225e-4501-8459-1e936ca9e79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
