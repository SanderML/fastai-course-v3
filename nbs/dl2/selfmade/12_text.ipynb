{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d897bc-30bd-4360-81ff-b0aacaf64b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_11a import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69fdf29-749f-4bd9-b737-99689b71e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f1f69-6796-4e0a-9a21-fd9c70ad44d9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f874858-fc73-41a9-9192-0278db52324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a88a674-ce4d-49c3-b350-eaff3803fd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/sandmann/.fastai/data/imdb/ll.clas.pkl'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/imdb.vocab'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/ll_clas.pkl'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/tmp_clas'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/tmp_lm'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/test'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/ld.pkl'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/unsup'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/train'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/README')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2388332a-0560-4ea1-ae50-d64ce9eb6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_file(fn):\n",
    "    with open(fn, 'r', encoding='utf8') as f: return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7eed27-57eb-4261-b82e-ee722e28060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TextList(ItemList):\n",
    "    @classmethod\n",
    "    def from_files(cls, path, extensions='.txt', recurse=True, include=None, **kwargs):\n",
    "        return cls(get_files(path, extensions, recurse, include), path, **kwargs)\n",
    "    \n",
    "    def get(self, i):\n",
    "        if isinstance(i, Path): return read_file(i)\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de323595-0a9e-458b-8501-a75add39c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f718c1b-bc7b-4858-a438-f062496ecb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be877148-59d8-441d-bf11-2db7ef49152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What could have been an excellent hostage movie was totally ruined by what apparently looks like a bored director ... there were so many directions that the movie could have taken ... a vampire slash-fest was not one of these!!! The last 45 mins. or so results in the movie being an absolutely ridiculous waste of time. ...and sex machine?? ... you gotta be kidding me! The acting talents of the likes of Juliette Lewis and Harvey Keitel (not to mention George Clooney) are completely wasted in this nonsensical movie. <br /><br />The director... Robert Rodriguez, known for his other gory flicks including el mariachi, desperado, once upon a time in Mexico, and the very recent sin city ... really holds your attention with the well executed first half ... which leads you to believe that you are in for an entertaining time ... but then apparently for no reason, and without any provocation, the madness starts ... there's even feeble attempts at parody and comedy ... truly exasperating!!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = il[0]; txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e397b3f1-551b-4484-8842-846ed94c2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b598eb0-6a2c-4ef4-9701-4104a13b0bce",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9166f0b-f934-40b7-887e-167bc3f45f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import spacy\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea88362b-8a56-431f-9f7d-47dabafe490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#special tokens\n",
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "\n",
    "def sub_br(t):\n",
    "    \"Replaces the <br /> by \\n\"\n",
    "    re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "    return re_br.sub(\"\\n\", t)\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around / and #\"\n",
    "    return re.sub(r'([/#])', r' \\1 ', t)\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t):\n",
    "    \"Replace repetitions at the character level: cccc -> TK_REP 4 c\"\n",
    "    def _replace_rep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "    \n",
    "def replace_wrep(t):\n",
    "    \"Replace word repetitions: word word word -> TK_WREP 3 word\"\n",
    "    def _replace_wrep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "    return re_wrep.sub(_replace_wrep, t)\n",
    "\n",
    "def fixup_text(x):\n",
    "    \"Various messy things we've seen in documents\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "    \n",
    "default_pre_rules = [fixup_text, replace_rep, replace_wrep, spec_add_spaces, rm_useless_spaces, sub_br]\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fb9ac0-f684-4fa5-95e9-973b28461471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxrep 4 d '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_rep('dddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09a417f-9522-4289-99fe-a501a9597cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxwrep 5 word  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_wrep('word word word word word ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc29df7c-bd53-4bb3-9808-4b67b0a75da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def replace_all_caps(x):\n",
    "    \"Replace tokens in ALL CAPS by their lower version and add `TK_UP` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t.isupper() and len(t) > 1: res.append(TK_UP); res.append(t.lower())\n",
    "        else: res.append(t)\n",
    "    return res\n",
    "\n",
    "def deal_caps(x):\n",
    "    \"Replace all Capitalized tokens in by their lower version and add `TK_MAJ` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t == '': continue\n",
    "        if t[0].isupper() and len(t) > 1 and t[1:].islower(): res.append(TK_MAJ)\n",
    "        res.append(t.lower())\n",
    "    return res\n",
    "\n",
    "def add_eos_bos(x): return [BOS] + x + [EOS]\n",
    "\n",
    "default_post_rules = [deal_caps, replace_all_caps, add_eos_bos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f673688-578d-418e-8478-2530d9b26725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'xxup', 'am', 'xxup', 'shouting']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_all_caps(['I', 'AM', 'SHOUTING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca1d8fd-00c8-4f28-bbc3-c9e8ccd80938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxmaj', 'my', 'name', 'is', 'xxmaj', 'jeremy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_caps(['My', 'name', 'is', 'Jeremy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f1fbf7-31cf-4abc-bb2e-be563e784ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from spacy.symbols import ORTH\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27139974-0a7e-4b47-838b-ce6990c9b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parallel(func, arr, max_workers=4):\n",
    "    if max_workers < 2: results = list(progress_bar(map(func, enumerate(arr)), total=len(arr)))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers) as ex:\n",
    "            return list(progress_bar(ex.map(func, enumerate(arr)), total=len(arr)))\n",
    "    if any([o is not None for o in results]): return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d056f970-e8d3-48fd-b852-bb12db53a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TokenizeProcessor(Processor):\n",
    "    def __init__(self, lang=\"en\", chunksize=2000, pre_rules=None, post_rules=None, max_workers=4): \n",
    "        self.chunksize,self.max_workers = chunksize,max_workers\n",
    "        self.tokenizer = spacy.blank(lang).tokenizer\n",
    "        for w in default_spec_tok:\n",
    "            self.tokenizer.add_special_case(w, [{ORTH: w}])\n",
    "        self.pre_rules  = default_pre_rules  if pre_rules  is None else pre_rules\n",
    "        self.post_rules = default_post_rules if post_rules is None else post_rules\n",
    "\n",
    "    def proc_chunk(self, args):\n",
    "        i,chunk = args\n",
    "        chunk = [compose(t, self.pre_rules) for t in chunk]\n",
    "        docs = [[d.text for d in doc] for doc in self.tokenizer.pipe(chunk)]\n",
    "        docs = [compose(t, self.post_rules) for t in docs]\n",
    "        return docs\n",
    "\n",
    "    def __call__(self, items): \n",
    "        toks = []\n",
    "        if isinstance(items[0], Path): items = [read_file(i) for i in items]\n",
    "        chunks = [items[i: i+self.chunksize] for i in (range(0, len(items), self.chunksize))]\n",
    "        toks = parallel(self.proc_chunk, chunks, max_workers=self.max_workers)\n",
    "        return sum(toks, [])\n",
    "    \n",
    "    def proc1(self, item): return self.proc_chunk([item])[0]\n",
    "    \n",
    "    def deprocess(self, toks): return [self.deproc1(tok) for tok in toks]\n",
    "    def deproc1(self, tok):    return \" \".join(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "566826b4-fd5d-49d9-9fd7-cec70f2b18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TokenizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c741bab4-e659-435f-a376-afb67f6c07ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What could have been an excellent hostage movie was totally ruined by what apparently looks like a bored director ... there were so many directions that the movie could have taken ... a vampire slash-fest was not one of these!!! The last 45 mins. or '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f1a140b-bb7a-47d0-8e6b-e48b4716c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'xxbos • xxmaj • what • could • have • been • an • excellent • hostage • movie • was • totally • ruined • by • what • apparently • looks • like • a • bored • director • ... • there • were • so • many • directions • that • the • movie • could • have • taken • ... • a • vampire • slash • - • fest • was • not • one • of • these • ! • ! • ! • xxmaj • the • last • 45 • mins • . • or • so • results • in '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' • '.join(tp(il[:100])[0])[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e6157-7a12-4ff8-9585-f0a724b56ce8",
   "metadata": {},
   "source": [
    "# Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0b73a97-ac45-4dba-871b-f81a0f6fbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import collections\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    def __init__(self, vocab=None, max_vocab=60000, min_freq=2):\n",
    "        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n",
    "        \n",
    "    def __call__(self, items):\n",
    "        if self.vocab is None:\n",
    "            freq = Counter(p for o in items for p in o)\n",
    "            self.vocab = [o for o,c in freq.most_common(self.max_vocab) if c >= self.min_freq]\n",
    "            for o in reversed(default_spec_tok):\n",
    "                if o in self.vocab: self.vocab.remove(o)\n",
    "                self.vocab.insert(0, o)\n",
    "\n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int, {v:k for k,v in enumerate(self.vocab)})\n",
    "        return [self.proc1(o) for o in items]\n",
    "    \n",
    "    def proc1(self, item): return [self.otoi[o] for o in item]\n",
    "\n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    \n",
    "    def deproc1(self, idx): return [self.vocab[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd8b46bb-8690-4cd2-b6bf-49ba9f71febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_tok, proc_num = TokenizeProcessor(max_workers=8), NumericalizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eca24583-4135-4f41-a7b4-b320de5698c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 3.34 s, total: 25.6 s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%time ll = label_by_func(sd, lambda x: 0, proc_x=[proc_tok,proc_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "061e7312-eaf5-4990-9319-6abf2312e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj one of the problems with popular culture , especially when discussing the popular culture of the 1970s , is that mass media - especially television - is usually about four years behind \\' underground \\' media , primarily music . xxmaj many people think the \\' xxmaj woodstock xxmaj generation \" remained important throughout the 1970s ; actually , it was all over at xxmaj altamont in 1970 . xxmaj by 1972 , \\' underground \\' rock or the \\' counterculture \\' had moved east to xxmaj england and xxmaj led xxmaj zepplin , xxmaj black sabbath , and xxmaj david xxmaj bowie , early metal - heads and the so - called \\' glam - rockers , \\' who were all \\' peace and love \\' - not . xxmaj neither , in a darkly different vein , was xxmaj charles xxmaj manson \\'s \\' family . \\' \\n\\n xxmaj this obvious pilot for a television show ( that , thankfully , was never picked up by the networks ) is attempting to come to terms with a culture that was already as withered as yesterday \\'s flowers . xxmaj the script must have been lying around a few years - by the time it was produced , writer xxmaj carlino had already achieved recognition for tough xxmaj mafia revenge tales . xxmaj and the cultural references are all to \" xxmaj easy xxmaj rider \" and xxmaj woodstock ( 1969 ) . xxmaj the music referenced on the soundtrack is actually earlier , 1966 / 67 - at xxmaj woodstock xxmaj hendrix , xxmaj canned xxmaj heat , and xxmaj sly and the xxmaj family xxmaj stone had blasted this kind of folk - pop into oblivion . \\n\\n xxmaj the movie is about a middle - class family that goes on the road in order to meet hippies . xxmaj wow , man , xxunk , xxunk , it \\'s a groovy mind - blowing happening of a bag . xxmaj however , politics count for nothing - xxmaj vietnam ? some place in xxmaj asia , right ? \\n\\n xxmaj this average ( meaning stale and vacuous ) tv movie is only redeemed by xxmaj jeff xxmaj bridges \\' surprisingly mature performance as the young college drop - out who convinces his parents and grandma to \\' discover \\' ( hippie ) xxmaj america . xxmaj all the rest of the performances are standard tv fair by standard tv actors of the time . xxmaj the director xxunk himself of some nice location cinematography , but otherwise the film is a poor way to spend 90 minutes . \\n\\n i knew it was all over when xxmaj sal xxmaj mineo remarks of a young runaway ( who tells the other characters they are not really there ) : \" xxmaj she \\'s a latent existentialist . \" xxmaj wow , far out , groovy . \\n\\n a couple extra points for being \\' so bad it \\'s funny , \\' but if you do n\\'t care about the \\' 70 \\'s tv version of the \\' 60 \\'s , stay away . xxeos'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.train.x_obj(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "391b6698-38a3-4660-b50c-87566ef996cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ll, open(path/'ld.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5699a6a-854e-4a59-96af-9b7425d722bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ld.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359b2e2-21ee-49bf-9dde-9b3ec42601ee",
   "metadata": {},
   "source": [
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a28477c-5a94-4c1f-b277-8a102e85da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,HTML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfa0a698-1ee7-46ee-b644-6239088b3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = \"\"\"\n",
    "In this notebook, we will go back over the example of classifying movie reviews we studied in part 1 and dig deeper under the surface. \n",
    "First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the Processor used in the data block API.\n",
    "Then we will study how we build a language model and train it.\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ce75ef0-f94a-4388-82e2-b853e5e87301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "tokens = np.array(tp([stream]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91437ad1-6f37-43f0-84fc-9a9d9ebb1f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,seq_len = 6,15\n",
    "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3687455-9280-44e1-9022-7e1122916e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,bptt = 6,5\n",
    "for k in range(3):\n",
    "    d_tokens = np.array([tokens[i*seq_len + k*bptt: i*seq_len + (k+1)*bptt] for i in range(bs)])\n",
    "    df = pd.DataFrame(d_tokens)\n",
    "    display(HTML(df.to_html(index=False, header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c094e46c-0e14-4f35-aee6-31fb4ee33658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LM_PreLoader():\n",
    "    def __init__(self, data, bs=64, bptt=70, shuffle=False):\n",
    "        self.data,self.bs,self.bptt,self.shuffle = data,bs,bptt,shuffle\n",
    "        total_len = sum([len(t) for t in data.x])\n",
    "        self.n_batch = total_len // bs\n",
    "        self.batchify()\n",
    "        \n",
    "    def __len__(self): return ((self.n_batch-1) //self.bptt) * self.bs\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        source = self.batched_data[idx % self.bs]\n",
    "        seq_idx = (idx // self.bs) * self.bptt\n",
    "        return source[seq_idx: seq_idx+self.bptt], source[seq_idx+1: seq_idx+self.bptt+1]\n",
    "    \n",
    "    def batchify(self):\n",
    "        texts = self.data.x\n",
    "        if self.shuffle: texts = texts[torch.randperm(len(texts))]\n",
    "        stream = torch.cat([tensor(t) for t in texts])\n",
    "        self.batched_data = stream[:self.n_batch * self.bs].view(self.bs, self.n_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d777ff79-1853-47b5-b655-8e8a0ee29a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(LM_PreLoader(ll.valid, shuffle=True), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1357333b-ac6f-4457-87d3-a1a638575256",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(dl)\n",
    "x1, y1 = next(iter_dl)\n",
    "x2, y2 = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4bfbe02-e046-41a0-9af8-a405777cd02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70]), torch.Size([64, 70]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size(), y1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfdfa80f-877d-4e23-ad4f-748d82cf77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = proc_num.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7501342f-988d-4bab-8828-5da225fdb501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60003"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d4a35d0-66ca-47cb-a4d8-6551e3856d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,    7,   19,   29,   25,   12,  477,   13,   75,    9,    7,   16,\n",
       "         308,  357,   10,  206, 3027,   10, 1777,  893,   10,  757, 7178,   11,\n",
       "         208,   14,   42, 1003, 1288,   52,   32,  796, 7446, 7621,   12, 3468,\n",
       "        7274,    9,    7,   16,   91,   35,  600,    9,   24,    7,   16,  787,\n",
       "          88,   20,   52,   94,  795,   96,   42,  300,  103,   12,   29,   10,\n",
       "          16,   25,  702,   70, 9801,  244,   10,   11,   41,   48])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dab6b0d-c910-43cc-9859-a5d607691a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxmaj this movie was a waste of time . xxmaj it looks nice , pretty settings , nicely acted , appears earnest and seems to be leading somewhere so you stay tuned awaiting a meaningful payoff . xxmaj it does n't happen . \\n\\n xxmaj it surprised me that so much effort could be put into a movie , it was clearly very professionally done , and have an\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab[o] for o in x1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c71938aa-6b60-4cc1-8d03-aa6d5028d5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxmaj this movie was a waste of time . xxmaj it looks nice , pretty settings , nicely acted , appears earnest and seems to be leading somewhere so you stay tuned awaiting a meaningful payoff . xxmaj it does n't happen . \\n\\n xxmaj it surprised me that so much effort could be put into a movie , it was clearly very professionally done , and have an outcome\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab[o] for o in y1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26c6bc34-f13d-4234-86cf-388c287eb83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"outcome that seems nothing short of a b - movie . \\n\\n xxmaj save your precious time and see a good french film like xxmaj les xxmaj visiteurs ( funny ) , xxmaj jean de xxmaj xxunk or xxmaj manon of the xxmaj spring . i ca n't recall the language in xxmaj europa xxmaj europa , but that 's another xxmaj great film -- heavy but very worth viewing\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab[o] for o in x2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "286af825-06c5-43b1-8f17-74403c15cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_lm_dls(train_ds, valid_ds, bs, bptt, **kwargs):\n",
    "    return (DataLoader(LM_PreLoader(train_ds, bs, bptt, shuffle=True), batch_size=bs, **kwargs),\n",
    "            DataLoader(LM_PreLoader(valid_ds, bs, bptt, shuffle=False), batch_size=bs*2, **kwargs))\n",
    "\n",
    "def lm_databunchify(sd, bs, bptt, **kwargs):\n",
    "    return DataBunch(*get_lm_dls(sd.train, sd.valid, bs, bptt, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5eeb524-305b-4cbd-87ed-86fd76b60190",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 64, 70\n",
    "data = lm_databunchify(ll, bs, bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ed923-8a25-4d96-8b73-b14d380a9728",
   "metadata": {},
   "source": [
    "# Batching for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d19943d5-b067-4638-b06b-b0ecdef79163",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_cat = CategoryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78de6b4d-fd66-46b5-b228-51a987f288fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test'])\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='test'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_x=[proc_tok, proc_num], proc_y=proc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b95c3d9e-aeb7-4c60-9d38-95e8a3fff82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ll, open(path/'ll.clas.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "921a3a62-8faf-4dea-b432-84b3968d5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ll.clas.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b0d70a7-9441-4d6c-ab64-ce08e52f5ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/sandmann/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/train/neg'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " Path('/home/sandmann/.fastai/data/imdb/train/pos')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5f906e4-db98-46fc-a5c4-da619bd85e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxbos xxmaj note to xxmaj horror fans : xxmaj the only horror here is when you realized you just wasted 95 minutes of your life on a movie that \\'s so worthless it \\'s insulting . \\n\\n i watched this because : \\n\\n xxmaj the premise sounded slightly promising : xxmaj it \\'s not . xxmaj it \\'s just an excuse to use the same lame set pieces from other low - budget slasher films that were n\\'t good either . \\n\\n xxmaj the promise of naked forest nymphs sounded nice even if the movie turned out to be awful : xxmaj it \\'s not . xxmaj it \\'s so not . xxmaj the amateur cinematography makes sure the \" fallen angels \" are about as sexy as the average homeless person . \\n\\n xxmaj the name xxmaj tom xxmaj savini has a long history in the horror genre : xxmaj he \\'s the king of low - budget special effects and lower - budget acting . xxmaj come to think of it , xxmaj savini should have been a reason not to watch this movie . xxmaj it \\'s not that he \\'s bad , but he \\'s almost always in bad movies . xxmaj his only good role was in xxmaj from xxmaj dusk xxmaj till xxmaj dawn , and he \\'s been milking that at horror conventions ever since . \\n\\n xxmaj but let \\'s focus on the positive : xxmaj forest of the xxmaj damned is a great example of how not to make a movie . \\n\\n xxmaj everything else is a negative . xxmaj obviously the writer is allergic to originality . xxmaj the script is terrible . xxmaj that \\'s all a given after the first 10 minutes . xxmaj but the clueless pacing ; the way the director treats \" plot \" and \" characterization \" as a nuisance he thinks no one cares about anyway ; and the excruciatingly long and boring driving , walking , and nature sequences ( no doubt added to increase the running time to make the film qualify for distribution ) show a complete lack of aptitude for film and storytelling in general . \\n\\n xxmaj this is another good example of the number - one way you can tell if a movie is going to be bad : xxmaj if it \\'s written and directed by the same person , expect garbage . xxeos',\n",
       "  'neg'),\n",
       " ('xxbos xxmaj this film was a waste of time , even rented on dvd . xxmaj if super - speedy camera shots get any faster than this , we might as well pay twenty bucks to get in the laundromat , get popcorn , and watch the dryer spin . xxmaj jet xxmaj li is so much better than this . xxmaj one can only hope that he wo n\\'t be making deals anytime soon to make another cliche - ridden film like xxmaj the xxmaj one . \\n\\n xxmaj if there \\'s one film you should avoid , this is \" xxmaj the xxmaj one \" . xxeos',\n",
       "  'neg')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ll.train.x_obj(i), ll.train.y_obj(i)) for i in [1,1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4393967b-0d77-4e11-91bd-2cde9ef1b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __repr__(self):\n",
    "        return iter(sorted(list(range(len(self))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08cd9c9d-2251-4cbe-9c3e-3be3da6e696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs): self.data_source,self.key,self.bs = data_source,key,bs\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i: i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]\n",
    "        batch_idxs = torch.randperm(len(batches) - 2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e149707-0d73-4db2-8243-937d0a210997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_collate(samples, pad_idx=1, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i,  -len(s[0]):] = LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0])  ] = LongTensor(s[0])\n",
    "        \n",
    "    return res, tensor([s[1] for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1d6bb95-91cf-47ff-bc4f-b20c95f70306",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_sampler = SortishSampler(ll.train.x, key=lambda t: len(ll.train[int(t)][0]), bs=bs)\n",
    "train_dl = DataLoader(ll.train, bs, sampler=train_sampler, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36142cd0-6b35-42b4-bcb0-22185f873b0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;34m/home/sandmann/anaconda3/envs/fastbook/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m, in \u001b[0;32mrun_code\u001b[0m:\nLine \u001b[0;34m3441\u001b[0m:  exec(code_obj, \u001b[36mself\u001b[39;49;00m.user_global_ns, \u001b[36mself\u001b[39;49;00m.user_ns)\n",
      "In  \u001b[0;34m[71]\u001b[0m:\nLine \u001b[0;34m2\u001b[0m:     x,y = \u001b[36mnext\u001b[39;49;00m(iter_dl)\n",
      "File \u001b[0;34m/home/sandmann/anaconda3/envs/fastbook/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m, in \u001b[0;32m__next__\u001b[0m:\nLine \u001b[0;34m521\u001b[0m:   data = \u001b[36mself\u001b[39;49;00m._next_data()\n",
      "File \u001b[0;34m/home/sandmann/anaconda3/envs/fastbook/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m, in \u001b[0;32m_next_data\u001b[0m:\nLine \u001b[0;34m561\u001b[0m:   data = \u001b[36mself\u001b[39;49;00m._dataset_fetcher.fetch(index)  \u001b[37m# may raise StopIteration\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/sandmann/anaconda3/envs/fastbook/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m, in \u001b[0;32mfetch\u001b[0m:\nLine \u001b[0;34m44\u001b[0m:    data = [\u001b[36mself\u001b[39;49;00m.dataset[idx] \u001b[34mfor\u001b[39;49;00m idx \u001b[35min\u001b[39;49;00m possibly_batched_index]\n",
      "File \u001b[0;34m/home/sandmann/anaconda3/envs/fastbook/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m, in \u001b[0;32m<listcomp>\u001b[0m:\nLine \u001b[0;34m44\u001b[0m:    data = [\u001b[36mself\u001b[39;49;00m.dataset[idx] \u001b[34mfor\u001b[39;49;00m idx \u001b[35min\u001b[39;49;00m possibly_batched_index]\n",
      "File \u001b[0;34m/home/sandmann/repo/fastai-course-v3/nbs/dl2/selfmade/exp/nb_08.py\u001b[0m, in \u001b[0;32m__getitem__\u001b[0m:\nLine \u001b[0;34m145\u001b[0m:   \u001b[34mdef\u001b[39;49;00m \u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, idx): \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.x[idx], \u001b[36mself\u001b[39;49;00m.y[idx]\n",
      "File \u001b[0;34m/home/sandmann/repo/fastai-course-v3/nbs/dl2/selfmade/exp/nb_08.py\u001b[0m, in \u001b[0;32m__getitem__\u001b[0m:\nLine \u001b[0;34m59\u001b[0m:    res = \u001b[36msuper\u001b[39;49;00m().\u001b[32m__getitem__\u001b[39;49;00m(idx)\n",
      "File \u001b[0;34m/home/sandmann/repo/fastai-course-v3/nbs/dl2/selfmade/exp/nb_06.py\u001b[0m, in \u001b[0;32m__getitem__\u001b[0m:\nLine \u001b[0;34m86\u001b[0m:    \u001b[34mif\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(idx[\u001b[34m0\u001b[39;49;00m], \u001b[36mbool\u001b[39;49;00m):\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "iter_dl = iter(train_dl)\n",
    "x,y = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f3a3e-2d35-4914-89fb-87380f88919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i in range(x.size(0)): lengths.append(x.size(1) - (x[i]==1).sum().item())\n",
    "lengths[:5], lengths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88c388-24a0-45da-8d8e-33b558676083",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter_dl)\n",
    "lenghts = []\n",
    "for i in range(x.size(0)): lengths.append(x.size(1) - (x[i]==1).sum().item())\n",
    "lenghts[:5], lengths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ecdab-9a1a-4013-ae69-43ddd3e934ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e8430c-d90d-4ad6-be2c-2afaf5c8f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_clas_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    train_sampler = SortishSampler(train_ds.x, key=lambda t: len(train_ds.x[t]), bs=bs)\n",
    "    valid_sampler = SortSampler(valid_ds.x, key=lambda t: len(valid_ds.x[t]))\n",
    "    return (DataLoader(train_ds, bs, sampler=train_sampler, collate_fn=pad_collate, **kwargs),\n",
    "            DataLoader(valid_ds, bs*2, sampler=valid_sampler, collate_fn=pad_collate, **kwargs))\n",
    "\n",
    "def clas_databunchify(sd, bs, **kwargs):\n",
    "    return DataBunch(*get_clas_dls(sd.train, sd.valid, bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e5446-ba6e-40ed-becd-3e84b466beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 64,70\n",
    "data = clas_databunchify(ll, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa2c5ca-dd54-476e-84e8-3e00606bdca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12_text.ipynb to exp/nb_12.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 12_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf472ee-58ec-495c-8440-e4d621784637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
