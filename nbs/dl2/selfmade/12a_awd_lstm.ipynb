{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ed9941-84f5-4e40-a530-983afa27f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_12 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce247a0-4277-4f4a-b292-5e65d6245260",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2014458-0fe9-4d59-b06a-7d3062ec185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc64dd0-caa9-49bb-b4c0-8cec5a43697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0d2451-8479-43f4-83f4-7000df0ac419",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40847b6d-c225-4f03-9ef8-32048f097767",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_tok, proc_num = TokenizeProcessor(max_workers=8), NumericalizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b6ab50-b99a-4eff-abbf-b3bc5b997869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='45' class='' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [45/45 01:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:08<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = label_by_func(sd, lambda x: 0, proc_x=[proc_tok, proc_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90f95e0-326f-4930-a00c-e919d72db767",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ll, open(path/'ll_lm.pkl', 'wb'))\n",
    "pickle.dump(proc_num.vocab, open(path/'vocab_lm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3306aedc-8dc8-41fc-80fd-21903d011b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ll_lm.pkl', 'rb'))\n",
    "vocab = pickle.load(open(path/'vocab_lm.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813c28cf-b74e-4a80-b601-be692599f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 64,70\n",
    "data = lm_databunchify(ll, bs, bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d4b97-144d-43e1-bbc3-de31d1b6b24e",
   "metadata": {},
   "source": [
    "# AWD-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408c45fe-cc94-4087-b831-4482fff07b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        super().__init__()\n",
    "        self.ih = nn.Linear(ni,nh*4)\n",
    "        self.hh = nn.Linear(ni,nh*4)\n",
    "        \n",
    "    def forward(self, input, state):\n",
    "        h,c = state\n",
    "        gates = (self.ih(input) + self.hh(h)).chunk(4,1)\n",
    "        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n",
    "        cellgate = gates[3].tanh()\n",
    "        \n",
    "        c = (forgetgate * c) + (ingate * cellgate)\n",
    "        h = outgate * c.tanh()\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0579c366-17a0-438a-be91-53ec9626f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer(nn.Module):\n",
    "    def __init__(self, cell, *cell_args):\n",
    "        super().__init__()\n",
    "        self.cell = cell(*cell_args)\n",
    "        \n",
    "    def forward(self, input, state):\n",
    "        inputs = input.unbind(1)\n",
    "        outputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            out, state = self.cell(inputs[i], state)\n",
    "            outputs += [out]\n",
    "        return torch.stack(outputs, dim=1), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00bd4265-1019-487e-a160-8f3adb278412",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMLayer(LSTMCell, 300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c551b7-6274-408f-9b65-81c72c2b13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64, 70, 300)\n",
    "h = (torch.zeros(64, 300), torch.zeros(64, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3976c289-0cb5-4759-b6d6-d08aed724e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 ms ± 15.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y, h1 = lstm(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1730a1d1-3ae1-4d91-bc42-62717f82d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = lstm.cuda()\n",
    "x = x.cuda()\n",
    "h = (h[0].cuda(), h[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703298b2-b400-4024-bf20-2179de76da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_fn(f):\n",
    "    f()\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39aa7d82-150e-4563-a79e-c2e2cf39c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(lstm, x, h)\n",
    "time_fn(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe888786-ecab-4f8b-a0b6-a302b1e3499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.9 ms ± 5.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 time_fn(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb19fe-c6d3-40b0-95e4-55ff2fd3698a",
   "metadata": {},
   "source": [
    "## Builtin Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c40252f-2201-4c9d-9e41-d2a5f009a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(300, 300, 1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f61d1ec-6d53-4b0a-9859-c9c1d411f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64, 70, 300)\n",
    "h = (torch.zeros(1, 64, 300), torch.zeros(1, 64, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68206547-eb50-4008-bad3-59cb86825cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ms ± 21.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y,h1 = lstm(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41f2bd7c-1ccf-4b72-9ad5-6b6cec130e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = lstm.cuda()\n",
    "x = x.cuda()\n",
    "h = (h[0].cuda(), h[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e32ae54c-fd12-469a-a78a-f06d79adf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(lstm, x, h)\n",
    "time_fn(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3afbfc90-9de4-4f19-a073-c1193ce1343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.28 ms ± 144 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 time_fn(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64f5f6-d98b-4b4f-a870-9ed4aaecb463",
   "metadata": {},
   "source": [
    "## Jit version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcfa70-d1d2-41e3-a876-783b7eecd06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0c8b2a5-0437-462e-884a-dcabaebab515",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a51f3be-d974-4837-beb5-451b0ce98269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dropout_mask(x, sz, p):\n",
    "    return x.new(*sz).bernoulli_(1-p).div_(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "008fdfa6-2edb-417e-840f-74cc84497fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 2., 2., 0., 0.],\n",
       "        [0., 2., 2., 0., 2., 2., 2., 0., 2., 2.],\n",
       "        [2., 0., 2., 0., 2., 2., 0., 2., 0., 0.],\n",
       "        [0., 2., 0., 2., 2., 2., 2., 0., 2., 2.],\n",
       "        [2., 0., 2., 0., 0., 2., 0., 2., 2., 2.],\n",
       "        [2., 0., 0., 0., 0., 0., 0., 2., 0., 2.],\n",
       "        [2., 0., 2., 2., 0., 2., 2., 2., 2., 2.],\n",
       "        [2., 0., 0., 0., 0., 0., 2., 2., 0., 2.],\n",
       "        [2., 2., 0., 2., 2., 0., 2., 0., 2., 2.],\n",
       "        [0., 0., 2., 2., 2., 2., 0., 2., 0., 2.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10,10)\n",
    "mask = dropout_mask(x, (10,10), 0.5); mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18ca9e91-d2b8-43a0-b0c7-6c90c312a7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 0., 2., 2., 0., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2., 0., 0., 0., 2., 2.]],\n",
       "\n",
       "        [[2., 0., 2., 0., 0., 2., 0., 2., 0., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2., 0., 0., 2., 2., 0.]],\n",
       "\n",
       "        [[2., 0., 0., 2., 2., 0., 2., 0., 2., 2.]],\n",
       "\n",
       "        [[0., 2., 2., 0., 0., 0., 0., 2., 2., 0.]],\n",
       "\n",
       "        [[2., 0., 2., 0., 0., 2., 0., 0., 2., 0.]],\n",
       "\n",
       "        [[2., 0., 2., 2., 2., 0., 0., 2., 2., 2.]],\n",
       "\n",
       "        [[0., 2., 2., 2., 0., 2., 2., 0., 0., 0.]],\n",
       "\n",
       "        [[2., 0., 0., 2., 2., 0., 0., 2., 2., 0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = dropout_mask(x, (10,1,10), 0.5); mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00062215-23a7-401a-b84a-009154a74689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.6299), tensor(1.0464))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x*mask).std(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f732534c-e3e4-4c87-9b93-184cc205a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p == 0: return x\n",
    "        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n",
    "        return x * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdfc5b78-34a8-4df4-9420-4899efcc796f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6063,  0.6775, -1.9772,  0.1402, -0.3584, -0.2261, -0.2862],\n",
       "          [ 0.2561,  0.9484, -1.2634, -1.1033,  0.7754,  1.2954,  2.1382],\n",
       "          [-1.2494, -0.2679, -0.3921,  0.4358,  0.0893, -1.3988,  0.5875]],\n",
       " \n",
       "         [[ 0.4595, -0.6507, -0.7962, -1.0126,  1.4215, -0.5194,  1.2283],\n",
       "          [ 0.2415, -0.7655, -0.0630, -0.5322,  0.1524,  0.2143, -0.3106],\n",
       "          [ 0.9479, -1.1344,  0.2207,  0.7560, -1.2366,  1.1719, -0.4460]],\n",
       " \n",
       "         [[-1.8169, -1.6285, -2.6410,  1.4514,  0.9844, -1.4719, -1.0307],\n",
       "          [-1.1995,  0.8590,  0.1494,  1.4166, -0.9586, -0.6480, -0.7661],\n",
       "          [-0.2177,  2.8074, -0.6074, -0.5804,  0.2179, -0.1285,  0.6921]]]),\n",
       " tensor([[[-0.8661,  0.9679, -2.8246,  0.0000, -0.5120, -0.0000, -0.4089],\n",
       "          [ 0.3658,  1.3548, -1.8049, -0.0000,  1.1078,  0.0000,  3.0546],\n",
       "          [-1.7848, -0.3828, -0.5601,  0.0000,  0.1275, -0.0000,  0.8393]],\n",
       " \n",
       "         [[ 0.6564, -0.0000, -1.1375, -0.0000,  2.0308, -0.0000,  1.7547],\n",
       "          [ 0.3450, -0.0000, -0.0901, -0.0000,  0.2177,  0.0000, -0.4437],\n",
       "          [ 1.3541, -0.0000,  0.3154,  0.0000, -1.7666,  0.0000, -0.6372]],\n",
       " \n",
       "         [[-2.5956, -0.0000, -3.7729,  0.0000,  0.0000, -0.0000, -1.4725],\n",
       "          [-1.7135,  0.0000,  0.2135,  0.0000, -0.0000, -0.0000, -1.0944],\n",
       "          [-0.3110,  0.0000, -0.8677, -0.0000,  0.0000, -0.0000,  0.9888]]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = RNNDropout(0.3)\n",
    "tst_input = torch.randn(3,3,7)\n",
    "tst_input, dp(tst_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1d5f476-e462-4c75-b203-c43dfe574399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "\n",
    "WEIGHT_HH = 'weight_hh_l0'\n",
    "\n",
    "class WeightDropout(nn.Module):\n",
    "    def __init__(self, module, weight_p=[0.], layer_names=[WEIGHT_HH]):\n",
    "        super().__init__()\n",
    "        self.module,self.weight_p,self.layer_names = module, weight_p, layer_names\n",
    "        for layer in self.layer_names:\n",
    "            w = getattr(self.module, layer)\n",
    "            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))\n",
    "            self.module._parameters[layer] = F.dropout(w, p=self.weight_p, training=False)\n",
    "            \n",
    "    def _setweights(self):\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            self.module._parameters[layer] = F.dropout(raw_w, self.weight_p, self.training)\n",
    "            \n",
    "    def forward(self, *args):\n",
    "        self._setweights()\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f6f561b-626b-451b-a8ec-cb6f581a8b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4979,  0.4344],\n",
       "        [ 0.4838, -0.4228],\n",
       "        [-0.6440, -0.0390],\n",
       "        [-0.2952, -0.3687],\n",
       "        [ 0.4696,  0.5331],\n",
       "        [ 0.6828, -0.0539],\n",
       "        [-0.4510, -0.3763],\n",
       "        [ 0.4732, -0.6334]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(5, 2)\n",
    "dp_module = WeightDropout(module, 0.4)\n",
    "getattr(dp_module.module, WEIGHT_HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6da28a52-0f79-4831-a6d4-58c661478e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8299,  0.0000],\n",
       "        [ 0.0000, -0.7047],\n",
       "        [-0.0000, -0.0650],\n",
       "        [-0.4920, -0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 1.1380, -0.0898],\n",
       "        [-0.7517, -0.6271],\n",
       "        [ 0.0000, -0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_input = torch.randn(4,20,5)\n",
    "h = (torch.zeros(1,20,2), torch.zeros(1,20,2))\n",
    "x,h = dp_module(tst_input, h)\n",
    "getattr(dp_module.module, WEIGHT_HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ecbcae7-010e-49ae-8841-cc880b127d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EmbeddingDropout(nn.Module):\n",
    "    def __init__(self, emb, embed_p):\n",
    "        super().__init__()\n",
    "        self.emb,self.embed_p = emb,embed_p\n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    "        \n",
    "    def forward(self, words, scale=None):\n",
    "        if self.training and self.embed_p != 0:\n",
    "            size = (self.emb.weight.size(0), 1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, self.embed_p)\n",
    "            masked_embed = self.emb.weight * mask\n",
    "        else: masked_embed = self.emb.weight\n",
    "        if scale: masked_embed.mul_(scale)\n",
    "        \n",
    "        return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm, self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfa0d0bd-daa4-4c32-a214-117b00fe03b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 3.1045, -1.1391, -2.0346,  1.6329,  0.0320,  2.5144,  0.9208],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.7919, -0.6989, -0.9279,  0.7615, -1.1240, -2.0632,  4.0006]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = nn.Embedding(100, 7, padding_idx=1)\n",
    "enc_dp = EmbeddingDropout(enc, 0.5)\n",
    "tst_input = torch.randint(0, 100, (5,))\n",
    "enc_dp(tst_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1bb67-67f6-4620-8d5f-7169a5045a44",
   "metadata": {},
   "source": [
    "# Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8770dc36-e97a-44ed-bbc3-443e09213b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_detach(h):\n",
    "    return h.detach() if type(h) == torch.Tensor else tuple(to_detach(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c0e389-f466-4a77-934d-d66884abf4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AWD_LSTM(nn.Module):\n",
    "    \"AWD-LSTM inspired by https://arxiv.org/abs/1708.02182.\"\n",
    "    initrange=0.1\n",
    "    \n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5):\n",
    "        super().__init__()\n",
    "        self.bs,self.emb_sz,self.n_hid,self.n_layers = 1,emb_sz,n_hid,n_layers\n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.emb_dp = EmbeddingDropout(self.emb, embed_p)\n",
    "        self.rnns = [nn.LSTM(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz), 1, batch_first=True) for l in range(n_layers)]\n",
    "        self.rnns = nn.ModuleList([WeightDropout(rnn, weight_p) for rnn in self.rnns])\n",
    "        self.emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for _ in range(n_layers)])\n",
    "        \n",
    "    def forward(self, input):\n",
    "        bs,sl = input.size()\n",
    "        if bs != self.bs:\n",
    "            self.bs = bs\n",
    "            self.reset()\n",
    "        \n",
    "        raw_output = self.input_dp(self.emb_dp(input))\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn, hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = to_detach(new_hidden)\n",
    "        return raw_outputs, outputs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]\n",
    "        \n",
    "    def _one_hidden(self, l):\n",
    "        nh = self.n_hid if l != self.n_layers - 1 else self.emb_sz\n",
    "        return next(self.parameters()).new(1, self.bs, nh).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6277b08f-9064-4b2e-a12c-c57cf489a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinearDecoder(nn.Module):\n",
    "    def __init__(self, n_out, n_hid, output_p, tie_encoder=None, bias=True):\n",
    "        super().__init__()\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "        else: init.kaiming_uniform_(self.decoder.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.output_dp(outputs[-1]).contiguous()\n",
    "        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        return decoded, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "880fc701-e9ed-411f-b8fb-ac23b74a060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SequentialRNN(nn.Sequential):\n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(self, 'reset'): c.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a925e02-e19b-428d-8e40-1f72e068ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_language_model(vocab_sz, emb_sz, n_hid, n_layers, pad_token, output_p=0.4, hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5, tie_weights=True, bias=True):\n",
    "    rnn_enc = AWD_LSTM(vocab_sz, emb_sz, n_hid, n_layers, pad_token, hidden_p, input_p, embed_p, weight_p)\n",
    "    enc = rnn_enc.emb if tie_weights else None\n",
    "    return SequentialRNN(rnn_enc, LinearDecoder(vocab_sz, emb_sz, output_p, tie_encoder=enc, bias=bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8db7696e-5f9f-4215-b458-f2dcd68234b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_pad = vocab.index(PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f207181d-c286-40f8-8617-08dd527f49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(len(vocab), 300, 300, 2, tok_pad)\n",
    "tst_model = tst_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae8d0842-be45-4902-ac7c-ac544c5ff33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a4c67f-9c2f-49af-87a7-182ffaf2cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tst_model(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e7b12c9-9263-4d7e-bfa4-c1975ec30fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06b6cab3-838b-4fc4-8ac3-86a020a7b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded, raw_outputs, outputs = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64056566-9cc9-4540-b729-dc6a31276602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4480, 60003])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92160c7d-dced-4887-82c9-f8b8e8fd5140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4480"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad9f2ffc-3af2-4f31-b56e-ac6008e689da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([64, 70, 300]), torch.Size([64, 70, 300])],\n",
       " [torch.Size([64, 70, 300]), torch.Size([64, 70, 300])])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.size() for o in raw_outputs], [o.size() for o in outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1815138-b862-4a36-a9e5-8de952deaf7f",
   "metadata": {},
   "source": [
    "## Callbacks to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9564391e-1205-4dd1-97ed-106831843c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GradientClipping(Callback):\n",
    "    def __init__(self, clip=None): self.clip = clip\n",
    "    def after_backward(self):\n",
    "        if self.clip: nn.utils.clip_grad_norm_(self.run.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d31ec638-d106-4afc-b85e-4be742696109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNTrainer(Callback):\n",
    "    def __init__(self, α, β): self.α,self.β = α,β\n",
    "    \n",
    "    def after_pred(self):\n",
    "        self.raw_out, self.out = self.pred[1], self.pred[2]\n",
    "        self.run.pred = self.pred[0]\n",
    "        \n",
    "    def after_loss(self):\n",
    "        # AR and TAR\n",
    "        if self.α != 0.: self.run.loss += self.α * self.out[-1].float().pow(2).mean()\n",
    "        if self.β != 0.:\n",
    "            h = self.raw_out[-1]\n",
    "            if h.size(1) > 1: self.run.loss += self.β * (h[:,1:] - h[:, :-1]).float().pow(2).mean()\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        if hasattr(self.dl.dataset, 'batchify'): self.dl.dataset.batchify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab4fb46e-c578-42ba-bbaa-28d3e0e909c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cross_entropy_flat(input, target):\n",
    "    bs, sl = target.size()\n",
    "    return F.cross_entropy(input.view(bs * sl, -1), target.view(bs * sl))\n",
    "\n",
    "def accuracy_flat(input, target):\n",
    "    bs, sl = target.size()\n",
    "    return accuracy(input.view(bs * sl, -1), target.view(bs * sl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "822dcc7c-2653-46de-a256-6c80f333f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz, nh, nl = 300, 300, 2\n",
    "model = get_language_model(len(vocab), emb_sz, nh, nl, tok_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1fce128-b968-430a-8278-318ea147e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [partial(AvgStatsCallback, accuracy_flat),\n",
    "      CudaCallback, Recorder, ProgressCallback,\n",
    "      partial(GradientClipping, 0.1),\n",
    "      partial(RNNTrainer, α=2., β=1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27c73c7d-3d65-476f-b864-38d34839fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, data, cross_entropy_flat, lr=5e-3, cb_funcs=cbs, opt_func=adam_opt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3554c0a7-7712-4bd8-8a2f-4f7365c9ed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy_flat</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy_flat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.00 GiB (GPU 0; 4.00 GiB total capacity; 2.32 GiB already allocated; 6.87 MiB free; 2.35 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18343/4262498760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repo/fastai-course-v3/nbs/dl2/selfmade/exp/nb_09b.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, cbs, reset_opt)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_begin_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_begin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/fastai-course-v3/nbs/dl2/selfmade/exp/nb_09b.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/fastai-course-v3/nbs/dl2/selfmade/exp/nb_09b.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, xb, yb)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18343/1703657814.py\u001b[0m in \u001b[0;36mcross_entropy_flat\u001b[0;34m(input, target)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_entropy_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastbook/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.00 GiB (GPU 0; 4.00 GiB total capacity; 2.32 GiB already allocated; 6.87 MiB free; 2.35 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ebdb7-896e-4d49-8d73-a0c352dcd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python notebook2script.py 12a_awd_lstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ff560-b62e-4226-953d-13c5fb06cfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
