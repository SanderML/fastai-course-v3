{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7eb847-e780-4533-b83b-dfc18113bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0221bb4-ad89-45c6-9484-233a9f8aabc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2798974-b960-4e09-8647-ab2973208dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_06 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6433a655-0d70-4f33-bc85-33ba3927ec11",
   "metadata": {},
   "source": [
    "# ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfaddeea-d2b3-454f-acd4-1ef11f9a233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77c8f3c-26b6-41b7-9466-07315869958f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.9649e-10), tensor(1.0000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d8b0c3-b393-4afe-be14-64f1aadc3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3a9f17-0a33-4cf6-a8c0-eeeb66dc3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh, bs = 50, 512\n",
    "c = y_train.max().item() + 1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d645caf9-d98e-4b51-ba1c-cbd0e70e9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a52630-ce04-449d-b62d-2041467ffe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_view = view_tfm(1,28,28)\n",
    "cbfs = [Recorder,\n",
    "        CudaCallback,\n",
    "       partial(AvgStatsCallback, accuracy),\n",
    "       partial(BatchTransformXCallback, mnist_view)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ecaef40-3813-4b38-ad28-b5f1ed6314ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [8, 16, 32, 64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "688ffd30-41a9-4e49-8059-858f1c28dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, 0.5, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7806ab67-3a84-4bc7-b5d9-01a28feaffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.7427634765625, tensor(0.7600, device='cuda:0')]\n",
      "valid: [0.2911787109375, tensor(0.9130, device='cuda:0')]\n",
      "train: [0.14137265625, tensor(0.9566, device='cuda:0')]\n",
      "valid: [0.108356396484375, tensor(0.9647, device='cuda:0')]\n",
      "CPU times: user 2.61 s, sys: 471 ms, total: 3.08 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25443984-8f24-41b6-9329-e0a21dbd5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.mults = nn.Parameter(torch.ones(nf, 1, 1))\n",
    "        self.adds = nn.Parameter(torch.zeros(nf, 1, 1))\n",
    "        self.register_buffer('means', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('vars', torch.ones(1,nf,1,1))\n",
    "        \n",
    "    def update_stats(self, x):\n",
    "        m = x.mean((0,2,3), keepdim=True)\n",
    "        v = x.var((0,2,3), keepdim=True)\n",
    "        self.means.lerp_(m, self.mom)\n",
    "        self.vars.lerp_(v, self.mom)\n",
    "        return m, v\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            with torch.no_grad(): m,v = self.update_stats(x)\n",
    "        else: m, v = self.means, self.vars\n",
    "        x = (x - m) / (v + self.eps).sqrt()\n",
    "        return x * self.mults + self.adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c13f12e0-29e2-4174-958c-19c4ee9d24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, stride, padding=ks//2, bias=not bn),\n",
    "             GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(BatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b2ef0b9-2cf6-476f-bd44-8a88f98c31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learn_run(nfs, data, lr, layer, cbs=None, opt_func=None, uniform=False, **kwargs):\n",
    "    model = get_cnn_model(data, nfs, layer)\n",
    "    init_cnn(model, uniform=uniform)\n",
    "    return get_runner(model, data, lr, cbs, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94942c0c-bd62-48c7-ad73-9d926e08ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(m, uniform=False):\n",
    "    f = init.kaiming_uniform_ if uniform else init.kaiming_normal_\n",
    "    init_cnn_(m, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10607f0b-8727-4cee-9466-76a7e7719b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn_(m, f):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        f(m.weight, a=0.1)\n",
    "        if getattr(m, 'bias', None) is not None: m.bias.data.zero_()\n",
    "    for l in m.children(): init_cnn_(l, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de8690c4-1ef3-42b5-bcdc-8c6629923523",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, 0.9, conv_layer, cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59c261a4-1c3c-4a3c-a3c3-8071ece6b2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "    (1): GeneralRelu()\n",
       "    (2): BatchNorm()\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): GeneralRelu()\n",
       "    (2): BatchNorm()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): GeneralRelu()\n",
       "    (2): BatchNorm()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): GeneralRelu()\n",
       "    (2): BatchNorm()\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): GeneralRelu()\n",
       "    (2): BatchNorm()\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=1)\n",
       "  (6): Lambda()\n",
       "  (7): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12d341-d909-4b48-8909-88fde6267168",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hooks??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f9e0a-6aed-4b2f-85ba-92519b148b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_learn_run??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e46e9-7a99-48d1-a3cc-1460d92fd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Hooks(learn.model, append_stats) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10,4))\n",
    "    for h in hooks[:-1]:\n",
    "        ms, ss = h.stats\n",
    "        ax0.plot(ms[:10])\n",
    "        ax1.plot(ss[:10])\n",
    "        h.remove()\n",
    "    plt.legend(range(6));\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10,4))\n",
    "    for h in hooks[:-1]:\n",
    "        ms, ss, = h.stats\n",
    "        ax0.plot(ms)\n",
    "        ax1.plot(ss)\n",
    "    plt.legend(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a207fa20-ab86-49bf-b01c-2048a1ef9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, 1.0, conv_layer, cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced0f48a-3ad2-4ef3-bc0e-717a57233a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.24103836263020834, tensor(0.9240, device='cuda:0')]\n",
      "valid: [0.126695947265625, tensor(0.9594, device='cuda:0')]\n",
      "train: [0.0818512939453125, tensor(0.9747, device='cuda:0')]\n",
      "valid: [0.5217087890625, tensor(0.8484, device='cuda:0')]\n",
      "train: [0.062210355631510415, tensor(0.9809, device='cuda:0')]\n",
      "valid: [0.14971971435546874, tensor(0.9535, device='cuda:0')]\n",
      "CPU times: user 3.92 s, sys: 627 ms, total: 4.55 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f545699-55e9-4354-8900-ae2a3a306f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, stride, padding=ks//2, bias=not bn),\n",
    "             GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20f52f6e-8eec-4a25-8a2f-cd95ee9fdb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, 1., conv_layer, cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "781e12e4-6eef-40ad-96b1-ca03193f98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.20321240234375, tensor(0.9373, device='cuda:0')]\n",
      "valid: [0.239667431640625, tensor(0.9241, device='cuda:0')]\n",
      "train: [0.06327790934244791, tensor(0.9797, device='cuda:0')]\n",
      "valid: [0.07068351440429688, tensor(0.9785, device='cuda:0')]\n",
      "train: [0.04151160481770833, tensor(0.9872, device='cuda:0')]\n",
      "valid: [0.07696593627929688, tensor(0.9757, device='cuda:0')]\n",
      "CPU times: user 4.93 s, sys: 532 ms, total: 5.47 s\n",
      "Wall time: 4.86 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96b5153e-c946-4d2a-b34f-aa3a6bf41432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3, 0.7], [sched_lin(0.6, 2.), sched_lin(2., 0.1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b59eda-a565-4f27-94c9-ece983cb066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_layer, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f482268e-8750-458a-9cb4-0e7852777466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.21216072591145832, tensor(0.9360, device='cuda:0')]\n",
      "valid: [0.2795697265625, tensor(0.9163, device='cuda:0')]\n",
      "train: [0.0718368408203125, tensor(0.9775, device='cuda:0')]\n",
      "valid: [0.07884379272460937, tensor(0.9727, device='cuda:0')]\n",
      "train: [0.04805149332682292, tensor(0.9850, device='cuda:0')]\n",
      "valid: [0.190367919921875, tensor(0.9418, device='cuda:0')]\n",
      "train: [0.031479264322916665, tensor(0.9901, device='cuda:0')]\n",
      "valid: [0.04675704650878906, tensor(0.9856, device='cuda:0')]\n",
      "train: [0.018110154215494792, tensor(0.9947, device='cuda:0')]\n",
      "valid: [0.03555221252441406, tensor(0.9887, device='cuda:0')]\n",
      "train: [0.010334288533528645, tensor(0.9973, device='cuda:0')]\n",
      "valid: [0.03924672241210937, tensor(0.9863, device='cuda:0')]\n",
      "train: [0.0063715387980143225, tensor(0.9987, device='cuda:0')]\n",
      "valid: [0.03159510498046875, tensor(0.9898, device='cuda:0')]\n",
      "train: [0.004243774668375651, tensor(0.9995, device='cuda:0')]\n",
      "valid: [0.031404281616210936, tensor(0.9897, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c74a1e-4401-4844-bb89-c91e72d3f365",
   "metadata": {},
   "source": [
    "# More norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca378b-1981-4c27-a792-dd39935ab0a0",
   "metadata": {},
   "source": [
    "## Layer norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3a888f7-e719-41d4-81f2-dbf3addf9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    __constants__ = ['eps']\n",
    "    def __init__(self, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.mult = nn.Parameter(tensor(1.))\n",
    "        self.add = nn.Parameter(tensor(0.))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = x.mean((1,2,3), keepdim=True)\n",
    "        v = x.var((1,2,3), keepdim=True)\n",
    "        x = (x - m) / (v + self.eps).sqrt()\n",
    "        return x * self.mult + self.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "556f1fe0-4719-4f92-bfb8-6ce05a7da2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_ln(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, stride, padding=ks//2, bias=True),\n",
    "             GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(LayerNorm())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee286891-c410-40b5-84ea-9c8c69212329",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, 0.8, conv_ln, cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d48cbaf-ea9b-4613-8d13-2f1a71cd5285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [nan, tensor(0.1251, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0980, device='cuda:0')]\n",
      "train: [nan, tensor(0.0987, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0980, device='cuda:0')]\n",
      "train: [nan, tensor(0.0987, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0980, device='cuda:0')]\n",
      "CPU times: user 4.93 s, sys: 630 ms, total: 5.56 s\n",
      "Wall time: 4.96 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d2b01-3e08-4963-a57d-5a1dfc98b57a",
   "metadata": {},
   "source": [
    "# Instance Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10b0a5a5-6b5a-4d24-8a22-9b5869fe6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    __constants__ = ['eps']\n",
    "    def __init__(self, nf, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.mult = nn.Parameter(torch.ones(nf,1,1))\n",
    "        self.adds = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = x.mean((2,3), keepdim=True)\n",
    "        v = x.var((2,3), keepdim=True)\n",
    "        x = (x - m) / (v + self.eps).sqrt()\n",
    "        return x * self.mult + self.adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8a3a608-e22a-4eec-bcd1-3a3a6729433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_in(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, stride, padding=ks//2, bias=True),\n",
    "             GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(InstanceNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d59db183-60f8-46b7-841c-937bd0190548",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(nfs, data, 0.1, conv_in, cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b774616a-72cf-4fd4-be2d-d0d01caf42fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [nan, tensor(0.0987, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0980, device='cuda:0')]\n",
      "train: [nan, tensor(0.0987, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0980, device='cuda:0')]\n",
      "train: [nan, tensor(0.0987, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0980, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c76ab4f-0c91-42e7-9633-b1b3dd945486",
   "metadata": {},
   "source": [
    "# Fix small batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9de04de7-b50c-449c-9284-6fe21fc17b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, 2), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bc09e19-9a6a-4c20-bbff-878411bd649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf, eps=1e-5, momentum=0.1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1764865f-4b5d-40dd-b028-b0d3d023c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8832a6f-85d6-483e-9a70-90cd80196869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.3486611979166665, tensor(0.1752, device='cuda:0')]\n",
      "valid: [13775449.2928, tensor(0.1738, device='cuda:0')]\n",
      "CPU times: user 1min 36s, sys: 9.43 s, total: 1min 45s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "843c5cb1-ff2d-4f74-ae79-0c6128814332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningBatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.mults = nn.Parameter(torch.ones(nf,1,1))\n",
    "        self.adds = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('batch', tensor(0.))\n",
    "        self.register_buffer('count', tensor(0.))\n",
    "        self.register_buffer('step', tensor(0.))\n",
    "        self.register_buffer('dbias', tensor(0.))\n",
    "     \n",
    "    def update_stats(self, x):\n",
    "        bs, nc, *_ = x.shape\n",
    "        self.sums.detach_()\n",
    "        self.sqrs.detach_()\n",
    "        dims = (0,2,3)\n",
    "        s = x.sum(dims, keepdim=True)\n",
    "        ss = (x*x).sum(dims, keepdim=True)\n",
    "        \n",
    "        c = self.count.new_tensor(x.numel() / nc)\n",
    "        mom1 = 1 - (1 - self.mom) / math.sqrt(bs-1)\n",
    "        self.mom1 = self.dbias.new_tensor(mom1)\n",
    "        self.sums.lerp_(s, self.mom1)\n",
    "        self.sqrs.lerp_(ss, self.mom1)\n",
    "        self.count.lerp_(c, self.mom1)\n",
    "        self.dbias = self.dbias * (1 - self.mom1) + self.mom1\n",
    "        self.batch += bs\n",
    "        self.step += 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        sums = self.sums\n",
    "        sqrs = self.sqrs\n",
    "        c = self.count\n",
    "        if self.step < 100:\n",
    "            sums = sums / self.dbias\n",
    "            sqrs = sqrs / self.dbias\n",
    "            c = c / self.dbias\n",
    "        means = sums / c\n",
    "        vars = (sqrs/c).sub_(means*means)\n",
    "        \n",
    "        if bool(self.batch < 20): vars.clamp_min_(0.01)\n",
    "        x = (x - means).div_((vars.add_(self.eps)).sqrt())\n",
    "        return x.mul_(self.mults).add_(self.adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc683822-afc5-4803-8e3a-3ca96db94b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_rbn(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(RunningBatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03127d83-5acf-48c2-b730-362d6c5d38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_rbn, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f98bda38-82b2-4cbb-b505-9b1ca836ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a1ea605-4a96-4ee4-aa5a-56c4048a4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, 32), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e6a63c7-6884-4aeb-b5b8-e669e5377a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_rbn, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched_lin(1., 0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01bcb1ce-c210-4e52-bc45-48104ad51823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.14209744466145832, tensor(0.9557, device='cuda:0')]\n",
      "valid: [0.050409323120117186, tensor(0.9843, device='cuda:0')]\n",
      "CPU times: user 17.4 s, sys: 3.61 s, total: 21 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f32c1b61-0eed-45b1-b94f-0d7ca60e52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningBatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.mults = nn.Parameter(torch.ones(nf,1,1))\n",
    "        self.adds = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('count', tensor(0.))\n",
    "#         self.register_buffer('step', tensor(0.))\n",
    "#         self.register_buffer('dbias', tensor(0.))\n",
    "#         self.register_buffer('batch', tensor(0.))\n",
    "        self.batch = 0\n",
    "        self.register_buffer('factor', tensor(0.))\n",
    "        self.register_buffer('offset', tensor(0.))\n",
    "     \n",
    "    def update_stats(self, x):\n",
    "        bs, nc, *_ = x.shape\n",
    "        self.sums.detach_()\n",
    "        self.sqrs.detach_()\n",
    "        dims = (0,2,3)\n",
    "        s = x.sum(dims, keepdim=True)\n",
    "        ss = (x*x).sum(dims, keepdim=True)\n",
    "#         c = self.count.new_tensor(x.numel() / nc)\n",
    "        c = s.new_tensor(x.numel() / nc)\n",
    "    \n",
    "#         mom1 = 1 - (1 - self.mom) / math.sqrt(bs-1)\n",
    "        mom1 = s.new_tensor(1 - (1-self.mom) / math.sqrt(bs-1))\n",
    "#         self.mom1 = self.dbias.new_tensor(mom1)\n",
    "        self.sums.lerp_(s, mom1)\n",
    "        self.sqrs.lerp_(ss, mom1)\n",
    "        self.count.lerp_(c, mom1)\n",
    "#         self.dbias = self.dbias * (1 - self.mom1) + self.mom1\n",
    "        self.batch += bs\n",
    "#         self.step += 1\n",
    "        means = self.sums / self.count\n",
    "        varns = (self.sqrs / self.count).sub_(means*means)\n",
    "        if bool(self.batch < 20): varns.clamp_min_(0.01) \n",
    "        self.factor = self.mults / (varns + self.eps).sqrt()\n",
    "        self.offset = self.adds - means * self.factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        return x * self.factor + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6830e747-b9ba-43dc-8325-855dcb439c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_rbn, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched_lin(1., 0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7059cf52-9a22-4d45-9988-02692fce8a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.136450732421875, tensor(0.9576, device='cuda:0')]\n",
      "valid: [0.04484238891601563, tensor(0.9854, device='cuda:0')]\n",
      "CPU times: user 14.2 s, sys: 1.8 s, total: 16 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb752d1-9a4d-4b73-8a65-d9d5c0b64f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
