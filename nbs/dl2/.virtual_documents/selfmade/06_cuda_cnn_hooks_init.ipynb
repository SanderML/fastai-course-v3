get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")

get_ipython().run_line_magic("matplotlib", " inline")


#export 
from exp.nb_05b import *
torch.set_num_threads(2)


def get_data():
    mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),
                 get_items = get_image_files,
                 splitter = GrandparentSplitter('training', 'testing'),
                 get_y = parent_label)
    dls = mnist.dataloaders(untar_data(URLs.MNIST))
    x_train, y_train = zip(*dls.train_ds)
    x_valid, y_valid = zip(*dls.valid_ds)

    x_train = tensor(list(map(array, x_train)), dtype=torch.float32).view(len(dls.train_ds), -1)
    x_valid = tensor(list(map(array, x_valid)), dtype=torch.float32).view(len(dls.valid_ds), -1)
    y_train = tensor(y_train)
    y_valid = tensor(y_valid)
    
    x_train, x_valid = x_train / 255.0, x_valid / 255.0
    x_mean = x_train.mean()
    x_std = x_train.std()
    x_train, x_valid = normalize(x_train, x_mean, x_std), normalize(x_valid, x_mean, x_std)

    return x_train, y_train, x_valid, y_valid


x_train, y_train, x_valid, y_valid = get_data()


x_train.mean(), x_train.std()


nh, bs = 50, 512
c = y_train.max().item() + 1
loss_func = F.cross_entropy


get_ipython().run_line_magic('pinfo2',  'get_data')


get_ipython().run_line_magic('pinfo2',  'normalize')


data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)



